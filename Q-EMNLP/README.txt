### README ###

# Folders:
- data : train / dev / test sets
- models : trained models
- neuralnets : CNN, LSTM, CRF layers for neural network architecture
- pkl : pkl file in which the embeddings are stored

# Scripts:

1. create_train_dev_test_sets.py :
   Takes as input a folder with annotations. Outputs a randomly shuffled train, dev, and test set.

2. CNN-LSTM-CRF.py :
   Trains a CNN-BiLSTM-CRF model on the annotations in the 'data' folder. Takes as input the data folder, and the filepath to the pre-trained word embeddings.

3. RunModel_CoNLL_Format.py :
   Runs the train model on CoNLL format. This script is used to provide test labels to the test set. Outputs 'predictions_on_test_data.txt', which is used in the evaluation script.

4. evaluation.py :
   Generates a training history graph, entity label distribution dictionary, precision, recall and F1 scores, classification report per label, and a confusion matrix.
   Takes as input: file locations of the gold test data and system generated test data, location of train/dev/test folder, location of training_history.json

5. RunModel_on_folder.py :
   Runs the trained model on a folder of raw texts and outputs labeled texts in CoNNL format in the 'system_output' folder.

6. goods_timeline.py :
   Extracts the top n (user defined) most frequently traded goods and quantities from texts, aggregates the quantities per decade, which is visualized on a timeline. Takes as input the system labeled data (in the 'system_output' folder), the date metadata from the missiven ('../gm_dates.json'), and a unit conversion dictionary ('unit_conversions.json').

7. person_timeline.py :
   Extracts the top n (user defined) most frequently mentioned persons over time, normalized by the number of missives per decade. Takes as input a dictionary with date metadata from the missiven, and the folder with system labeled output ('system_output')

8. word_embeddings.py :
   Create word embeddings using gensim. Uses a custom made SpaCy tokeniser, to minimize intra-entity sentence splitting. Takes a corpus of texts as input.

# Files:
- word_embeddings.txt :
  pre-trained word embeddings trained on the Generale Missiven, Van Dam, and Memories van Ambon corpora. Used in 'Q-CNN-LSTM-CRF.py'

- model_summary.txt :
  Summary of model architecture

- training_history.json
  Training history of the trained model. Used in 'evaluation.py'

- predictions_on_test_data.txt
  System generated label predictions on test data, generated by 'RunModel_CoNLL_Format.py'

- unit_conversions.json
  Unit conversions. Used in 'goods_timeline.py'
